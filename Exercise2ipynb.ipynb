{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpcEUiKaDWQnQ1ZcyuKEKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rijan-Ja-Bhattarai/AI/blob/main/Exercise2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BxKVWi-EG3DM",
        "outputId": "3052c7f2-3c9e-4347-f477-4e7e8158f092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device Agnostic Code"
      ],
      "metadata": {
        "id": "Swc9495uHLEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "vL4ZXh4MIIHR"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create The Dataset"
      ],
      "metadata": {
        "id": "eJPNJvJoIOd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Known Parameters\n",
        "weight = 0.3\n",
        "bias = 0.9\n",
        "\n",
        "start = 1.\n",
        "end = 5.\n",
        "step = 0.01\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim = 1)\n",
        "y = weight * X + bias"
      ],
      "metadata": {
        "id": "SdSGMTNxIYL-"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "print(f\"Total Dataset Size: {X.shape}\")\n",
        "train_split = int(0.8 * len(X))\n",
        "\n",
        "X_train = X[:train_split]\n",
        "y_train = y[:train_split]\n",
        "\n",
        "X_test = X[train_split: ]\n",
        "y_test = y[train_split: ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDhFMrOqJPtl",
        "outputId": "27d4e0ac-1711-4aa2-8387-305d469f0d7c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Dataset Size: torch.Size([400, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of train set: {X_train.shape}\")\n",
        "print(f\"Shape of train set: {y_train.shape}\")\n",
        "print(f\"Shape of train set: {X_test.shape}\")\n",
        "print(f\"Shape of train set: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAXaOKcOJ8iY",
        "outputId": "04d977d2-2e7a-4405-e0a0-ffee06dde7c6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train set: torch.Size([320, 1])\n",
            "Shape of train set: torch.Size([320, 1])\n",
            "Shape of train set: torch.Size([80, 1])\n",
            "Shape of train set: torch.Size([80, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Function"
      ],
      "metadata": {
        "id": "tidkh81QKEhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_prediction(train_set = X_train.cpu().numpy(),\n",
        "                    train_label = y_train.cpu().numpy(),\n",
        "                    test_set = X_test.cpu().numpy(),\n",
        "                    test_label = y_test.cpu().numpy(),\n",
        "                    prediction = None):\n",
        "  plt.figure(figsize = (10, 7))\n",
        "\n",
        "  plt.scatter(train_set, train_label, c = \"blue\", s = 5,   label = \"Training Set\")\n",
        "  plt.scatter(test_set, test_label, c = \"red\", s = 5,   label = \"Testing Set\")\n",
        "\n",
        "  if prediction is not None:\n",
        "    plt.ylim(0, 6)\n",
        "    plt.grid(visible=True)\n",
        "    plt.scatter(test_set, prediction, c = \"green\", s = 5, label =  \"Prediction Set\")"
      ],
      "metadata": {
        "id": "EmDTe2Q0LVvC"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "rbDVWlkkMUzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear_layer = nn.Linear(in_features= 1,\n",
        "                                  out_features= 1,\n",
        "                                  bias = True)\n",
        "  def forward(self, X : torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(X)\n",
        "\n",
        "# Manual Seed for Weights and Bias\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Instance of The Model\n",
        "model = LinearRegressionModel()\n",
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7FNoIiRMWL8",
        "outputId": "1d7537fc-2543-43c5-bede-f361150ef4a1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.5964]])),\n",
              "             ('linear_layer.bias', tensor([0.8334]))])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS0eTqoDZ60r",
        "outputId": "3e483115-1933-4cd3-8c0a-590e4b3bbfac"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel(\n",
              "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Model"
      ],
      "metadata": {
        "id": "3IJDSQrEOEx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss Function\n",
        "Loss_fn = nn.L1Loss()\n",
        "\n",
        "# Optimizer\n",
        "Optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr = 0.01)"
      ],
      "metadata": {
        "id": "pi3A-2QvOV5Z"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_values = []\n",
        "test_loss = []\n",
        "loss_values = []\n",
        "\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "epochs = 3600\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # Training Mode\n",
        "  model.train()\n",
        "\n",
        "  # Forward Pass\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  # Loss Function\n",
        "  loss = Loss_fn(y_pred, y_train)\n",
        "\n",
        "  # Optimizer Zero Grad\n",
        "  Optimizer.zero_grad()\n",
        "\n",
        "  # Back Propagation\n",
        "  loss.backward()\n",
        "\n",
        "  # Optimizer Step\n",
        "  Optimizer.step()\n",
        "\n",
        "  ### Perform testing every 20 epochs\n",
        "  if epoch % 20 == 0:\n",
        "    # Put model in evaluation mode and setup inference context\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass\n",
        "      y_preds = model(X_test)\n",
        "      # 2. Calculate test loss\n",
        "      test_loss = Loss_fn(y_preds,y_test)\n",
        "      # Print out what's happening\n",
        "      print(f\"Epoch: {epoch} | Train loss: {loss:.3f} | Test loss: {test_loss:.3f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiPW0qmO-Ae",
        "outputId": "b57bc0e0-762c-4e8f-d94e-9af453cb3eee"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 20 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 40 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 60 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 80 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 100 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 120 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 140 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 160 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 180 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 200 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 220 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 240 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 260 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 280 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 300 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 320 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 340 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 360 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 380 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 400 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 420 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 440 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 460 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 480 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 500 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 520 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 540 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 560 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 580 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 600 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 620 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 640 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 660 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 680 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 700 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 720 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 740 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 760 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 780 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 800 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 820 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 840 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 860 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 880 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 900 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 920 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 940 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 960 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 980 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1000 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1020 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1040 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1060 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1080 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1100 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1120 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1140 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1160 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1180 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1200 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1220 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1240 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1260 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1280 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1300 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1320 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1340 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1360 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1380 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1400 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1420 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1440 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1460 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1480 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1500 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1520 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1540 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1560 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1580 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1600 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1620 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1640 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1660 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1680 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1700 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1720 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1740 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1760 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1780 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1800 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1820 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1840 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1860 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1880 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1900 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1920 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1940 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1960 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 1980 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2000 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2020 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2040 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2060 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2080 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2100 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2120 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2140 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2160 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2180 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2200 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2220 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2240 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2260 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2280 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2300 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2320 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2340 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2360 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2380 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2400 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2420 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2440 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2460 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2480 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2500 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2520 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2540 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2560 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2580 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2600 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2620 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2640 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2660 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2680 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2700 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2720 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2740 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2760 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2780 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2800 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2820 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2840 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2860 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2880 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2900 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2920 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2940 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2960 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 2980 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3000 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3020 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3040 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3060 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3080 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3100 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3120 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3140 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3160 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3180 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3200 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3220 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3240 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3260 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3280 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3300 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3320 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3340 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3360 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3380 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3400 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3420 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3440 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3460 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3480 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3500 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3520 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3540 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3560 | Train loss: 0.059 | Test loss: 0.005\n",
            "Epoch: 3580 | Train loss: 0.059 | Test loss: 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{model.state_dict()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtktylVCdrB8",
        "outputId": "f54d4e8a-0922-4523-ddd4-9d8fd398cb15"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict({'linear_layer.weight': tensor([[0.3372]], device='cuda:0'), 'linear_layer.bias': tensor([0.8628], device='cuda:0')})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_preds = model(X_test)\n",
        "\n",
        "y_preds.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBlR_vKBfj4k",
        "outputId": "137a9895-8d50-4505-f400-ed71b9f1444a"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize"
      ],
      "metadata": {
        "id": "SkxaRSuwQzIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_np = y_preds.detach().cpu().numpy()\n",
        "plot_prediction(prediction=y_preds_np)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "dB9Ozzaqc9DS",
        "outputId": "8e268bf9-5803-4c8c-90b7-9b6d0e6545f6"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save"
      ],
      "metadata": {
        "id": "fEqiDPubdBoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "MODEL_PATH = Path(\"Models\")\n",
        "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "MODEL_NAME = \"Exercise1.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Saving to {MODEL_SAVE_PATH}\")\n",
        "torch.save(model.state_dict(),\n",
        "           f = MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD1-xA62lALd",
        "outputId": "e69ab99a-d070-4557-d247-77964e169fc8"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving to Models/Exercise1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "A0ZDfdKrlyv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loaded_Model = LinearRegressionModel()\n",
        "\n",
        "Loaded_Model.load_state_dict(torch.load(f = MODEL_SAVE_PATH))\n",
        "\n",
        "Loaded_Model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBfz8BvOmEYI",
        "outputId": "74ad23be-e216-4bad-bd61-49c5a9e5ab89"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel(\n",
              "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loaded_Model.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  Loaded_Model_preds = Loaded_Model(X_test)"
      ],
      "metadata": {
        "id": "OExueHcImZOE"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds == Loaded_Model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SBnZWBpnIhw",
        "outputId": "601db043-b5c5-4e30-ae81-a46203be1a52"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True],\n",
              "        [True]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rV8Rhn_QnUD6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}